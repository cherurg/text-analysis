Реализовывалась векторная модель корпуса.

Сначала я собрал корпус из примерно 3000 статей на вики из раздела про компьютерные игры. Код (а заодно и сам корпус) доступен [здесь](https://github.com/cherurg/text-analysis/tree/master/corpus). Для его работы нужно выполнить `pip install wikipedia`. Работает в третьей версии питона. Сначала нужно собрать ссылки, запустив create_json.py. Этот скрипт создаст список из 4000 игр и сохранит его в json-файл.

После этого можно запускать code.py, который и скачает статьи по их названиям. Получится не ровно 4000, потому как в процессе парсинга некоторых статей возникают ошибки.

После сбора корпуса можно запустить скрипт [отсюда](https://github.com/cherurg/text-analysis/tree/master/d2).

В файле tfidf.py реализована векторная модель. Скрипт code.py создает списки нормализованных слов из текстов, а затем с помощью tfidf.py создаются вектора весов tfidf. После этого для каждой пары тектов можно посчитать меру подобия с помощью косинусной меры:

```python
for i in range(len(files)):
  for j in range(len(files)):
    table.cos(files[i], files[j])
```

```python
A = [table.cos(files[i], files[j]) for i in range(len(files)) for j in range(len(files))]
```

A - матрица.
